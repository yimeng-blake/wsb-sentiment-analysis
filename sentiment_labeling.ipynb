{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Glop6D39fFfL",
        "outputId": "4ca91dba-b5a5-444a-b6c4-a72f0617e914"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed file saved successfully to labeled_wsb.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from transformers import pipeline, AutoTokenizer\n",
        "\n",
        "file_path = \"processed_wsb.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "pipe = pipeline(\"text-classification\", model=\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\", device=0)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")\n",
        "\n",
        "# Define a function to truncate the text properly based on token count\n",
        "def analyze_sentiment(text):\n",
        "    # Encode the text with truncation and max length\n",
        "    encoded_text = tokenizer(text, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "    result = pipe(tokenizer.decode(encoded_text['input_ids'][0], skip_special_tokens=True))[0]\n",
        "    return result\n",
        "\n",
        "# Check if MergedColumn exists in the data\n",
        "if 'MergedColumn' not in df.columns:\n",
        "    raise ValueError(\"The file does not contain a 'MergedColumn' column.\")\n",
        "\n",
        "# Apply the pipeline to the MergedColumn with proper token-level truncation\n",
        "results = df['MergedColumn'].apply(lambda x: analyze_sentiment(str(x)))\n",
        "\n",
        "# Add sentiment and confidence as new columns\n",
        "df['SentimentLabel'] = results.apply(lambda x: x['label'])\n",
        "df['Confidence'] = results.apply(lambda x: x['score'])\n",
        "\n",
        "# Save the updated DataFrame back to a CSV\n",
        "output_file = \"labeled_wsb.csv\"\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Processed file saved successfully to {output_file}\")\n"
      ]
    }
  ]
}